{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tn_bootcamp.ipynb","provenance":[{"file_id":"1CZSkkNJu8NA7pL5SOr8lqWlBbYZmnMNF","timestamp":1638850537043}],"collapsed_sections":["W8mGdPQdQIUK","_n8EqfusMRog","bhzV9kLSE6IX","38sU0MXO-E-B","W9bcbVV8CKfB","A6m9ZBZ13NyR","4-i1OWyVG6F0","mMrtQKMfG-9y"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["Copyright 2021 Google LLC\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");\n","you may not use this file except in compliance with the License.\n","You may obtain a copy of the License at\n","\n","    https://www.apache.org/licenses/LICENSE-2.0\n","\n","Unless required by applicable law or agreed to in writing, software\n","distributed under the License is distributed on an \"AS IS\" BASIS,\n","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","See the License for the specific language governing permissions and\n","limitations under the License."],"metadata":{"id":"ZZVNvhHHGzi9"}},{"cell_type":"markdown","metadata":{"id":"JntDk894pfVE"},"source":["# Instructions and Imports\n","\n","Got to File -> Save a copy in Drive to get your own copy of this notebook to play with.\n","\n","You may need to go to Edit -> Notebook settings and switch the Runtime type to Python 3 to get all of the code cells to run properly"]},{"cell_type":"code","metadata":{"id":"eqFy1GrzAwLm"},"source":["import numpy as np\n","from numpy import linalg as LA\n","import itertools"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_n8EqfusMRog"},"source":["# Part 1"]},{"cell_type":"markdown","metadata":{"id":"ygw134WwNWVg"},"source":["## Review of SVD and EVD"]},{"cell_type":"markdown","metadata":{"id":"2FFR_Kj4ZFqJ"},"source":["### Eigenvalue decomposition\n","\n","Any Hermitian matrix $M$ can be decomposed as\n","\n","$$\n","M = U D U^\\dagger\n","$$\n","\n","where $U$ is a unitary matrix and $D$ is a diagonal matrix. The diagonal entries of $D$ are the __*eigenvalues*__ of $M$.\n","\n"]},{"cell_type":"code","metadata":{"id":"5O503FaiZZUr","colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"status":"ok","timestamp":1556723229178,"user_tz":420,"elapsed":497,"user":{"displayName":"Stefan Leichenauer","photoUrl":"https://lh4.googleusercontent.com/-hh66BL9-FlA/AAAAAAAAAAI/AAAAAAAAAAw/uIdmReH_rCg/s64/photo.jpg","userId":"17498417252028123799"}},"outputId":"bcde174e-70f8-49c2-e5d2-13b0f9d82f4f"},"source":["A = np.random.rand(3,3)\n","M = A @ A.T\n","\n","D, U = LA.eigh(M) # D is returned as a vector\n","\n","print(M)\n","print()\n","M2 = U @ np.diag(D) @ np.conj(U.T) # Conjugation not always needed\n","print(M2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0.75955649 0.69358755 0.92804705]\n"," [0.69358755 0.6683539  0.87430683]\n"," [0.92804705 0.87430683 1.54889477]]\n","\n","[[0.75955649 0.69358755 0.92804705]\n"," [0.69358755 0.6683539  0.87430683]\n"," [0.92804705 0.87430683 1.54889477]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z_jIctpPYnpk"},"source":["### Singular value decomposition\n","\n","Any $n \\times m$ matrix $M$ with complex entries can be decomposed as\n","\n","$$\n","M = U S V^\\dagger\n","$$\n","\n","where $U$ is an $n \\times n$ unitary matrix, $V$ is an $m \\times m$ unitary matrix, and $S$ is an $n \\times m$ matrix with non-negative entries on the diagonal and zeros everywhere else.\n","\n","The diagonal entries in $S$ are called __*singular values*__. The singular values of $M$ and coincide with the positive square roots of the eigenvalues of $M^\\dagger M$ and $M M^\\dagger$, which we can deduce from the following equations:\n","$$\n","M^\\dagger M = V S^2 V^\\dagger\n","$$\n","$$\n","MM^\\dagger = US^2 U^\\dagger\n","$$"]},{"cell_type":"code","metadata":{"id":"MNt0F0SZArzz","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1556723337925,"user_tz":420,"elapsed":645,"user":{"displayName":"Stefan Leichenauer","photoUrl":"https://lh4.googleusercontent.com/-hh66BL9-FlA/AAAAAAAAAAI/AAAAAAAAAAw/uIdmReH_rCg/s64/photo.jpg","userId":"17498417252028123799"}},"outputId":"e192ae3f-7dc9-4bc3-976e-ae5124ae9445"},"source":["M = np.random.rand(2, 3) + 1j * np.random.rand(2, 3)\n","U, singular_values, Vh = LA.svd(M)\n","S = np.zeros((2, 3))\n","np.fill_diagonal(S, singular_values)\n","\n","print(M)\n","print()\n","M2 = U @ S @ Vh\n","print(M2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0.77123556+0.81610524j 0.92066534+0.9464577j  0.62123552+0.16641422j]\n"," [0.73588229+0.42478892j 0.04569124+0.66379687j 0.84702903+0.77728491j]]\n","\n","[[0.77123556+0.81610524j 0.92066534+0.9464577j  0.62123552+0.16641422j]\n"," [0.73588229+0.42478892j 0.04569124+0.66379687j 0.84702903+0.77728491j]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zKOZQYeAQ03i","colab":{"base_uri":"https://localhost:8080/","height":161},"executionInfo":{"status":"ok","timestamp":1556723362891,"user_tz":420,"elapsed":716,"user":{"displayName":"Stefan Leichenauer","photoUrl":"https://lh4.googleusercontent.com/-hh66BL9-FlA/AAAAAAAAAAI/AAAAAAAAAAw/uIdmReH_rCg/s64/photo.jpg","userId":"17498417252028123799"}},"outputId":"4fb75741-67a5-413d-fb02-10bc80d8cbcc"},"source":["print(f'singular values: {singular_values}')\n","print(f'squares of singlar values: {singular_values**2}')\n","print()\n","\n","Mh = np.conjugate(np.transpose(M))\n","\n","print('M Mh')\n","D, U = LA.eigh(M @ Mh)\n","print(D)\n","print()\n","print('Mh M')\n","D, U = LA.eigh(Mh @ M)\n","print(D)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["singular values: [2.30804502 0.7596754 ]\n","squares of singlar values: [5.32707181 0.57710671]\n","\n","M Mh\n","[0.57710671 5.32707181]\n","\n","Mh M\n","[7.20076883e-16 5.77106706e-01 5.32707181e+00]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HekrsLdxNZvP"},"source":["## MPS"]},{"cell_type":"markdown","metadata":{"id":"poZ0YiYSRtKm"},"source":["tensorSVD is a helper function used for making an MPS. The idea of it is that it does the reshaping of a tensor into a matrix for SVD, and then reshapes the U and V back into tensors for you."]},{"cell_type":"code","metadata":{"id":"Nnuv2pAhMUKg"},"source":["def tensorSVD(T,uinds,svd_threshold=1E-16):\n","  \"\"\"Computes the  SVD of an N-index tensor\n","  \n","  Args:\n","    T: Tensor to decompose\n","    uinds: List of indices forming the \"left\" effective index. These indices\n","      belong to the U tensor, and the rest belong to Vh.\n","    svd_threshold: Singular values smaller than this are truncated.\n","  \n","  Returns:\n","    tenU: Left tensor of the SVD.\n","    tenS: Diagonal matrix of singular values.\n","    tenV: Right tensor of the SVD.\n","  \"\"\"\n","  NT = len(T.shape)\n","  Nu = len(uinds)\n","  dest = range(Nu) # array 0,1,2,...\n","  pT = np.moveaxis(T,uinds,dest)\n","  udims = [pT.shape[n] for n in range(Nu)]\n","  vdims = [pT.shape[n] for n in range(Nu,NT)]\n","  uD = np.prod(udims)\n","  vD = np.prod(vdims)\n","  rpT = np.reshape(pT,[uD,vD])\n","  U,S,V = LA.svd(rpT,full_matrices=False)\n","\n","  # Determine truncation size:\n","  n_svd = len(S)\n","  for ix in range(n_svd):\n","    if S[ix] < svd_threshold:\n","      n_svd = ix\n","      break\n","  # Perform the truncation:\n","  truncU = U[:,0:n_svd]\n","  truncV = V[0:n_svd,:]\n","  truncS = S[0:n_svd]\n","  \n","  # Restore tensor structure to truncated U, S, V:\n","  udims.append(n_svd)\n","  vdims.insert(0,n_svd)\n","  tenU = np.copy(np.reshape(truncU,udims))\n","  tenV = np.copy(np.reshape(truncV,vdims))\n","  tenS = np.diag(truncS)\n","  return tenU,tenS,tenV"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jax9E04jMW9R"},"source":["def makeParityIndicator(num_bits):\n","  \"\"\"Creates an indicator tensor for the parity dataset. The indicator is a\n","  tensor with 2**num_bits entries and shape (2,)*num_bits.\n","\n","  Example: \n","    psi4 = makeParityIndicator(4)\n","    psi[0,0,0,0] = 1\n","    psi[0,0,0,1] = 0\n","\n","  Args:\n","    num_bits: Length of the input strings for the indicator.\n","\n","  Returns:\n","    psi: Indicator tensor.\n","  \"\"\"\n","  psi = np.zeros((2,)*num_bits)\n","  for bits in itertools.product([0, 1], repeat=num_bits):\n","    if sum(bits) % 2 == 0:\n","      psi[bits] = 1\n","  #psi += 1E-14*np.random.randn(*psi.shape)\n","  return psi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4tp7jGocuJfm"},"source":["We can compress the parity indicator into a MPS form by a sequence of SVDs, as explained in the lecture. The following code block"]},{"cell_type":"code","metadata":{"id":"MSe399NEMZVR","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1556723539945,"user_tz":420,"elapsed":273,"user":{"displayName":"Stefan Leichenauer","photoUrl":"https://lh4.googleusercontent.com/-hh66BL9-FlA/AAAAAAAAAAI/AAAAAAAAAAw/uIdmReH_rCg/s64/photo.jpg","userId":"17498417252028123799"}},"outputId":"1e8bb2d0-47b1-41c1-bb7d-70699a227c94"},"source":["# Create indicator for four-bit parity.\n","psi4 = makeParityIndicator(4)\n","\n","# Create the MPS tensors via a sequence of SVDs.\n","U1,S1,V1 = tensorSVD(psi4,[0])\n","print(\"V1.shape = \", V1.shape)\n","M2 = np.tensordot(S1, V1,[1,0])\n","print(\"M2.shape = \", M2.shape)\n","U2,S2,V2 = tensorSVD(M2, [0,1])\n","print(\"V2.shape = \", V2.shape)\n","M3 = np.tensordot(S2, V2, [1,0])\n","print(\"M3.shape = \", M3.shape)\n","U3,S3,V3 = tensorSVD(M3, [0,1])\n","print(\"V3.shape = \", V3.shape)\n","M4 = np.tensordot(S3, V3, [1,0])\n","print(\"M4.shape = \", M4.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["V1.shape =  (2, 2, 2, 2)\n","M2.shape =  (2, 2, 2, 2)\n","V2.shape =  (2, 2, 2)\n","M3.shape =  (2, 2, 2)\n","V3.shape =  (2, 2)\n","M4.shape =  (2, 2)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fHylAA8DvRom"},"source":["In this scheme, the four MPS tensors consist of each of the $U$ tensors from the SVDs for all but the final tensor. We can see their shapes here:"]},{"cell_type":"code","metadata":{"id":"4AB_voTLMbqB","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1556723567858,"user_tz":420,"elapsed":432,"user":{"displayName":"Stefan Leichenauer","photoUrl":"https://lh4.googleusercontent.com/-hh66BL9-FlA/AAAAAAAAAAI/AAAAAAAAAAw/uIdmReH_rCg/s64/photo.jpg","userId":"17498417252028123799"}},"outputId":"60a8a139-e013-4b0b-e3eb-ffc2d43b65dc"},"source":["print(\"U1.shape = \",U1.shape)\n","print(\"U2.shape = \",U2.shape)\n","print(\"U3.shape = \",U3.shape)\n","print(\"M4.shape = \",M4.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["U1.shape =  (2, 2)\n","U2.shape =  (2, 2, 2)\n","U3.shape =  (2, 2, 2)\n","M4.shape =  (2, 2)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Id_EAuNgvrby"},"source":["We can interpret the function of these MPS tensors by looking at which entries are nonzero. In particular, for $U2$ we have the following:"]},{"cell_type":"code","metadata":{"id":"9Y4JOHLhMdYg","colab":{"base_uri":"https://localhost:8080/","height":197},"executionInfo":{"status":"ok","timestamp":1556723594051,"user_tz":420,"elapsed":865,"user":{"displayName":"Stefan Leichenauer","photoUrl":"https://lh4.googleusercontent.com/-hh66BL9-FlA/AAAAAAAAAAI/AAAAAAAAAAw/uIdmReH_rCg/s64/photo.jpg","userId":"17498417252028123799"}},"outputId":"c993f117-fb49-4347-ad49-ab9174d00b2d"},"source":["print(\"These are the non-zero elements\")\n","print(round(np.sqrt(2)*U2[0,0,0]))\n","print(round(np.sqrt(2)*U2[1,1,0]))\n","print(round(np.sqrt(2)*U2[1,0,1]))\n","print(round(np.sqrt(2)*U2[0,1,1]))\n","\n","print(\"These elements should be zero\")\n","print(round(np.sqrt(2)*U2[0,0,1]))\n","print(round(np.sqrt(2)*U2[1,1,1]))\n","print(round(np.sqrt(2)*U2[1,0,0]))\n","print(round(np.sqrt(2)*U2[0,1,0]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["These are the non-zero elements\n","-1.0\n","-1.0\n","1.0\n","1.0\n","These elements should be zero\n","0.0\n","0.0\n","0.0\n","0.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bhzV9kLSE6IX"},"source":["# Part 2\n","\n","In this section we will walk through the creation of simple Tree Tensor Neworks (TTNs) using the density matrix method. These examples are phrased as multipart exercises, so you might try to code up the solution yourself before looking ahead."]},{"cell_type":"markdown","metadata":{"id":"XH5AKb1L6vWJ"},"source":["### Problem 1\n","\n","#### (i) \n","We begin by defining the tensor \n","$$\n","A_{ijkm} = \\sqrt{i+2j+3k+4l + 5m}\n","$$\n","where $i,j,k,l, m$ are each two-dimensional indices. That is, each one can take on the value $0$ or $1$. Initialize this tensor as a numpy array."]},{"cell_type":"code","metadata":{"id":"wkGvwAcT9XXE"},"source":["# Your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"38sU0MXO-E-B"},"source":["#### Solution (i)"]},{"cell_type":"code","metadata":{"id":"FcJ8Anmn7WXs","colab":{"base_uri":"https://localhost:8080/","height":493},"executionInfo":{"status":"ok","timestamp":1556667904202,"user_tz":420,"elapsed":390,"user":{"displayName":"Chase Roberts","photoUrl":"https://lh5.googleusercontent.com/-xtWBmLN9Jg4/AAAAAAAAAAI/AAAAAAAAASE/2IfPSyykstA/s64/photo.jpg","userId":"05619688024558850615"}},"outputId":"5ad3c219-0064-4bf8-b059-ee0e82c5fe84"},"source":["d = 2 # index dimensions\n","A = np.zeros((d,d,d,d,d))\n","for i in range(d):\n","    for j in range(d):\n","        for k in range(d):\n","            for l in range(d):\n","                for m in range(d):\n","                    A[i,j,k,l,m] = np.sqrt(i + 2*j + 3*k + 4*l + 5*m)\n","print(A.shape)\n","print(A)\n"," "],"execution_count":null,"outputs":[{"output_type":"stream","text":["(2, 2, 2, 2, 2)\n","[[[[[0.         2.23606798]\n","    [2.         3.        ]]\n","\n","   [[1.73205081 2.82842712]\n","    [2.64575131 3.46410162]]]\n","\n","\n","  [[[1.41421356 2.64575131]\n","    [2.44948974 3.31662479]]\n","\n","   [[2.23606798 3.16227766]\n","    [3.         3.74165739]]]]\n","\n","\n","\n"," [[[[1.         2.44948974]\n","    [2.23606798 3.16227766]]\n","\n","   [[2.         3.        ]\n","    [2.82842712 3.60555128]]]\n","\n","\n","  [[[1.73205081 2.82842712]\n","    [2.64575131 3.46410162]]\n","\n","   [[2.44948974 3.31662479]\n","    [3.16227766 3.87298335]]]]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8QuDIG7G-JOX"},"source":["#### (ii)\n","\n","Using the appropriate density matrices, form isometries $W_L$ and $W_R$ that transform $A$ into the tree tensor network shown (truncating internal indices to dimension $\\chi=2$).\n","Store $W_L$, $W_R$, and $B$ as arrays. These form the truncated TTN representaiton of $A$."]},{"cell_type":"code","metadata":{"id":"gK6RS6Vv9bqj"},"source":["# Your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W9bcbVV8CKfB"},"source":["#### Solution (ii)"]},{"cell_type":"markdown","metadata":{"id":"dyxD95cJ3Yuw"},"source":[""]},{"cell_type":"code","metadata":{"id":"gabR4JW0BsXG","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1556667917859,"user_tz":420,"elapsed":412,"user":{"displayName":"Chase Roberts","photoUrl":"https://lh5.googleusercontent.com/-xtWBmLN9Jg4/AAAAAAAAAAI/AAAAAAAAASE/2IfPSyykstA/s64/photo.jpg","userId":"05619688024558850615"}},"outputId":"83c08a7a-da88-4389-8e85-4453354d9f9a"},"source":["chi = 2 # Set bond dimension for truncations.\n","\n","# (a)form left density matrix and isometry\n","rho_L = A.reshape(d**2,d**3) @ A.reshape(d**2,d**3).T\n","D_L,U_L = LA.eigh(rho_L)\n","W_L = (U_L[:,(d**2-chi):]).reshape(d,d,chi)\n","\n","# (b) form right density matrix and isometry\n","rho_R = A.reshape(d**3,d**2).T @ A.reshape(d**3,d**2)\n","D_R,U_R = LA.eigh(rho_R)\n","W_R = (U_R[:,(d**2-chi):]).reshape(d,d,chi)\n","\n","# (c) form B tensor\n","B = np.einsum('ijklm,ijn,lmp->nkp',A,W_L,W_R)\n","print(B)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[[-1.1132985  -0.32372118]\n","  [-0.29164375  0.19986162]]\n","\n"," [[-0.84368511  9.69206703]\n","  [ 0.65763726 11.97641663]]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GqxbxYcQAkfg"},"source":["#### (iii)\n","\n","Check the accuracy of the truncated TTN by computing the truncation error $\\epsilon = \\|A-A_\\text{recover}\\|/\\|A\\|$, with the recovered tensor $A_\\text{recover}$ given by contracting the tree.\n","Here $\\| \\cdot \\|$ is the Frobenius norm that is implemented in numpy as `numpy.linalg.norm`."]},{"cell_type":"code","metadata":{"id":"txedzwm59gH5"},"source":["# Your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A6m9ZBZ13NyR"},"source":["#### Solution (iii)"]},{"cell_type":"code","metadata":{"id":"bC4FmQfbBtla","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1556667921102,"user_tz":420,"elapsed":331,"user":{"displayName":"Chase Roberts","photoUrl":"https://lh5.googleusercontent.com/-xtWBmLN9Jg4/AAAAAAAAAAI/AAAAAAAAASE/2IfPSyykstA/s64/photo.jpg","userId":"05619688024558850615"}},"outputId":"b9b90bd3-a6f7-46a3-db3d-9d4b4a388a32"},"source":["# check truncation error\n","A_recover = np.einsum('fkg,ijf,lmg->ijklm',B,W_L,W_R)\n","err_tot = LA.norm(A-A_recover) / LA.norm(A)\n","\n","print(err_tot)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.008103590433912287\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mxiB_9APCpub"},"source":["### Problem 2\n","\n","In this problem we'll train a TTN to approximate a batch of images, where again the approximation comes from truncating to bond dimension $\\chi =2$. The image set we're going to consider consists of five images with five pixels each, but the method is general and you should try repeating the exercise for a different set of images."]},{"cell_type":"markdown","metadata":{"id":"xHWb96xKETYY"},"source":["#### (i)\n","\n","Using the density matrix approach approximate the given set of images using the TTN shown below (truncating internal indices to bond dimension $\\chi=2$)."]},{"cell_type":"code","metadata":{"id":"Ht3gqQFFERpm"},"source":["chi = 2 # set bond dimension for truncations\n","\n","# define image data\n","image_data = np.array([[0,1,1,0,1],[1,1,0,0,1],[1,0,1,0,1],\n","                      [1,1,0,1,0],[0,1,1,0,1],[1,0,1,0,1]])\n","n_samples = image_data.shape[0]\n","n_pixels = image_data.shape[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w-kzcHzj9kKZ"},"source":["# Your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4-i1OWyVG6F0"},"source":["#### Solution (i)"]},{"cell_type":"code","metadata":{"id":"vFxktkcoqBtV"},"source":["###############################################################\n","def images_to_sparse(images):\n","  \"\"\"Creates a sparse tensor representation of image data (one-hot encoding)\n","  \n","  Args:\n","    images: Array of shape (M,N). M is the number of samples, N is the number\n","      of pixels\n","      \n","  Returns:\n","    pixel_tensors: list of length N, where pixel_tensors[k] is an array of \n","      shape (P,M) representing the one-hot encoding of the kth pixels.\n","  \"\"\"\n","  \n","  pixel_tensors = []\n","  for pixel_loc in range(images.shape[1]):\n","      pixel_tensors.append(np.array([(1-images[:,pixel_loc]),images[:,pixel_loc]]))\n","  \n","  return pixel_tensors\n","\n","###############################################################\n","def compute_scalar_products(pixel_tensors):\n","  \"\"\"Creates the matrix of scalar products from a list of pixel_tensors.\n","  \n","  Args:\n","    pixel_tensors: list of tensors, where pixel_tensors[k] is an array of \n","        shape (P,M) representing the one-hot encoding of the kth pixels.\n","      \n","  Returns:\n","    scalar_matrix: array of shape (M,M), formed from the product over pixels k\n","      of the outer product of pixel_tensors[k] with itself.\n","  \"\"\"\n","  \n","  M = pixel_tensors[1].shape[1]\n","  scalar_matrix = np.ones((M,M))\n","  for pixel in pixel_tensors:\n","      scalar_matrix = scalar_matrix * (pixel.T @  pixel)\n","  return scalar_matrix\n","\n","###############################################################\n","def sparse_to_dense(pixel_tensors):\n","  \"\"\"Creates a dense tensor from a list of pixel_tensors.\n","  \n","  Args:\n","    pixel_tensors: list of N tensors, where pixel_tensors[k] is an array of \n","        shape (P,M) representing the one-hot encoding of the kth pixels.\n","      \n","  Returns:\n","    dense_tensor: array with N dimensions, where dim of kth index kth is equal \n","      to the dim P of the kth tensor.\n","  \"\"\"\n","  \n","  dense_tensor = pixel_tensors[0]\n","  dims_P = [dense_tensor.shape[0]]\n","  for pixel in pixel_tensors[1:]:\n","      dim_temp = pixel.shape[0]\n","      dense_tensor = np.kron(dense_tensor,np.ones((dim_temp,1))) * np.kron(np.ones((np.prod(dims_P),1)),pixel)\n","      dims_P.append(dim_temp)\n","  return np.sum(dense_tensor,1).reshape(dims_P)\n","\n","###############################################################\n","\n","\n","# export image data to sparse tensor format\n","V = images_to_sparse(image_data)\n","\n","# (a) compute left density matrix\n","gamma_L = compute_scalar_products(V[2:4])\n","V_L = np.einsum('im,jm->ijm',V[0],V[1])\n","rho_L = V_L.reshape((4,n_samples)) @ gamma_L @ (V_L.reshape((4,n_samples))).T\n","# compute left isometry\n","D_L, U_L = LA.eigh(rho_L)\n","W_L = U_L[:,(4-chi):].reshape(2,2,chi)\n","\n","# (b) compute right density matrix \n","gamma_R = compute_scalar_products(V[0:2])\n","V_R = np.einsum('im,jm->ijm',V[3],V[4])\n","rho_R = V_R.reshape((4,n_samples)) @ gamma_R @ (V_R.reshape((4,n_samples))).T\n","# compute right isometry\n","D_R, U_R = LA.eigh(rho_R)\n","W_R = U_R[:,(4-chi):].reshape(2,2,chi)\n","\n","# (c) coarse-grain image data using isometries to form B tensor\n","V_Ltemp = np.einsum('ijk,ijl->kl',W_L,V_L)\n","V_Rtemp = np.einsum('ijk,ijl->kl',W_R,V_R)\n","B = sparse_to_dense([V_Ltemp,V[2],V_Rtemp])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ATjOU4ojGQXY"},"source":["#### (ii)\n","\n","Check the accuracy of your result by contracting the TTN into a single dense tensor and comparing with the dense tensor representation of the original data."]},{"cell_type":"code","metadata":{"id":"MUJRVKeJ9m1Q"},"source":["# Your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mMrtQKMfG-9y"},"source":["#### Solution (ii)"]},{"cell_type":"markdown","metadata":{"id":"zBEHE-zkkb5J"},"source":["We can check the accuracy using the Frobenius norm, just like in the previous problem.\n","\n","In this case, the example was chosen to allow perfect compression with $\\chi=2$, so the total error just comes from machine precision."]},{"cell_type":"code","metadata":{"id":"R4QH8MjuGuYX","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1556667929676,"user_tz":420,"elapsed":322,"user":{"displayName":"Chase Roberts","photoUrl":"https://lh5.googleusercontent.com/-xtWBmLN9Jg4/AAAAAAAAAAI/AAAAAAAAASE/2IfPSyykstA/s64/photo.jpg","userId":"05619688024558850615"}},"outputId":"9d11c0ad-ba3c-4a97-9f4c-b8a8e67d38be"},"source":["# check accuracy\n","A_recover = np.einsum('fkg,ijf,lmg->ijklm',B,W_L,W_R)\n","A_initial = sparse_to_dense(V)\n","err_tot = LA.norm(A_recover-A_initial)\n","\n","print(err_tot)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["3.1401849173675503e-16\n"],"name":"stdout"}]}]}